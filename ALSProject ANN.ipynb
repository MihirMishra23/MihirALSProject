{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import soundfile as sf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio(x: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    middle = np.where(x == max(x[int(len(x)*0.1):int(len(x)*0.95)]))[0][0]\n",
    "    minI, maxI = middle, middle\n",
    "    while minI > 0 and max(abs(x[minI:minI+500])) > 0.1:\n",
    "        minI -= 50\n",
    "    while maxI < len(x) and max(abs(x[maxI-500:maxI])) > 0.1:\n",
    "        maxI += 50\n",
    "    return x[minI-500:maxI+1000] if minI > 500 else x[minI:maxI+1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(fn: str) -> tuple:\n",
    "    path = Path(fn)\n",
    "    if fn == None:\n",
    "        print(\"Not valid File\")\n",
    "    \n",
    "    # checks to see if processed file already exists, and doesn't reprocess if it does\n",
    "    '''if Path(\"/\".join(path.parts[:-1])+\"/.Processed/p\"+path.name).is_file():\n",
    "        file = \"/\".join(path.parts[:-1])+\"/.Processed/p\"+path.name\n",
    "        time = librosa.get_duration(filename=file)\n",
    "        return librosa.load(file, sr = int(44100/time))'''\n",
    "        \n",
    "    #loads and trims audio\n",
    "    amplitudes, sr = librosa.load(fn)\n",
    "    amplitudes = trim_audio(amplitudes)\n",
    "\n",
    "    #creates a .Processed folder\n",
    "    strdir = \"/\".join(path.parts[:-1])+\"/.Processed/\"\n",
    "    try:\n",
    "        os.mkdir(strdir)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    #saves the processed audio file into a new audio file in the .Processed folder\n",
    "    newFilename = strdir + 'p' + path.name\n",
    "    sf.write(newFilename, amplitudes, sr)\n",
    "    \n",
    "    #loads audio file amplitude values that standardize the length of the amplitude array\n",
    "    time = librosa.get_duration(filename=newFilename)\n",
    "    amplitudes, sr = librosa.load(newFilename, sr = int(44100/time))\n",
    "    return amplitudes, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        self.lr = learningrate\n",
    "        \n",
    "        self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        self.activiation_function = lambda x: 1/(1+np.exp(-x))\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        targets = np.array(targets_list, ndmin = 2).T\n",
    "        inputs = np.array(inputs_list, ndmin = 2).T\n",
    "        \n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activiation_function(hidden_inputs)\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activiation_function(final_inputs)\n",
    "        \n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1-final_outputs)), hidden_outputs.T)\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1-hidden_outputs)), inputs.T)\n",
    "    \n",
    "    def query(self, inputs_list):\n",
    "        inputs = np.array(inputs_list, ndmin = 2).T\n",
    "        \n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activiation_function(hidden_inputs)\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activiation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wordlist() -> dict:\n",
    "    #reads the wordlist csv into a dictionary for easy retrieval\n",
    "    #Ex. CW100 corresponds to the word \"Yes\"\n",
    "    with open('UASpeech/speaker_wordlist.csv', mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        word_dict = {rows[1]:rows[0] for rows in reader}\n",
    "    del word_dict['FILE NAME']\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_from_filename(fn: str, word_dict: dict) -> str:\n",
    "    #retrievs the word based on the code used in the file\n",
    "    path = Path(fn)\n",
    "    fn = path.name.split('_')\n",
    "    return word_dict[fn[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 44100\n",
    "hidden_nodes = 1000\n",
    "output_nodes = 100\n",
    "learning_rate = 0.2\n",
    "\n",
    "nn = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "training_list = []\n",
    "testing_list = []\n",
    "for i in range(1, 101):\n",
    "    for j in range(1, 4):\n",
    "        filename = f\"UASpeech/audio/M16/M16_B{j}_CW{i}_M5.wav\"\n",
    "        if j == 2:\n",
    "            testing_list.append(np.insert(process_audio(filename)[0], 0, i))\n",
    "        else:\n",
    "            training_list.append(np.insert(process_audio(filename)[0], 0, i))\n",
    "training_list = np.array(training_list)\n",
    "testing_list = np.array(testing_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.000000e+00,  2.691697e-04,  3.421405e-04, ..., -5.401783e-03,\n",
       "       -4.076488e-03,  0.000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-75ff78edf252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-e5242997fcba>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs_list, targets_list)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mhidden_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwho\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwho\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_errors\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfinal_outputs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfinal_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwih\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_errors\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhidden_outputs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhidden_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train\n",
    "for i in range(20):\n",
    "    for word in training_list:\n",
    "        #print(int(word[0]), word.shape)\n",
    "        inputs = word[1:]\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        targets[int(word[0])-1] = 0.99\n",
    "        nn.train(inputs, targets)\n",
    "\n",
    "#test\n",
    "scorecard = []\n",
    "for test_word in testing_list:\n",
    "    expected = int(test_word[0])-1\n",
    "    received = int(np.argmax(nn.query(test_word[1:])))\n",
    "    scorecard.append(expected == received)\n",
    "    print(expected, received)\n",
    "\n",
    "#print(scorecard)\n",
    "print(f\"score = {sum(scorecard)/len(scorecard)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
